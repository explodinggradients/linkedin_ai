{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre requisites\n",
    "1. Clone this repo and do pip install -e .\n",
    "2. Have ragas-experimental installed \n",
    "3. DEV RAGAS APP TOKEN\n",
    "4. Clone git clone https://huggingface.co/datasets/explodinggradients/yann-lecun-wisdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md             yann_profile.json\n",
      "yann-lecun_posts.json yann_test.json\n"
     ]
    }
   ],
   "source": [
    "!ls ../yann-lecun-wisdom/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'question': 'What are your views on LLM limitations and their ability to generalize?', 'citations': ['7085498609558843392'], 'grading_notes': \"- LLMs can't generalize like humans.\\n- AI systems can't yet mimic human understanding.\\n- Highlight AI's limitations in text memorization.\\n- Current AI lacks adaptability to new contexts.\"}, {'question': \"What are Yann LeCun's thoughts on the future steps in AI, particularly the usefulness and limitations of current LLMs?\", 'citations': ['7140695461815820289', '7060629056785895424'], 'grading_notes': \"- Current LLMs have limitations but are still useful\\n- Discuss the balance between potential AI threats and benefits\\n- Outline practicality over perfection in AI\\n- Explore realistic AI advancements, not science fiction\\n- Encourage discussions on AI's current and future role\"}, {'question': 'How can countries like India foster AI innovation and development?', 'citations': ['7267674826373304322'], 'grading_notes': '- Suggest creating industry research labs with ambitions\\n- Use AI as an empirical science\\n- Address limitations of large language models\\n- Focus on world models, planning, and reasoning\\n- Encourage jumpstarting AI ecosystems'}, {'question': 'What are your views on the impact of political decisions on scientific research, specifically in the US?', 'citations': ['7303509065190551553'], 'grading_notes': '- Highlight funding cuts and resource reduction\\n- Mention staff firings and gag orders\\n- Discuss impact on scientific freedom\\n- Question long-term viability of US science\\n- Reflect on potential decline in scientific innovation'}, {'question': 'What are your opinions on receiving the Queen Elizabeth Prize for Engineering with respect to advancements in AI?', 'citations': ['7292877506095820803'], 'grading_notes': '- Honored by the Queen Elizabeth Prize recognition\\n- Shared prize with notable figures like Bengio, Hinton\\n- Prize focuses on engineering achievements\\n- Prestigious award in the engineering field\\n- Ceremony to attend in fall with royalty'}, {'question': 'What measures can Europe take to attract top AI scientists and researchers?', 'citations': ['7299096239625695232'], 'grading_notes': '- Emphasize competitive compensation and research freedom\\n- Highlight access to top students and collaborators\\n- Reduce administrative overhead for research funding\\n- Improve research facilities and industry collaboration\\n- Balance teaching and administrative duties'}, {'question': 'What are your current thoughts on the present and future of AI?', 'citations': ['7060629056785895424'], 'grading_notes': '- Focus on engineering challenges, not philosophical debates\\n- Highlight adaptability and transparent methods\\n- Promote user control and modular AI systems\\n- Emphasize empirical feedback and experimentation\\n- Encourage diverse, empowering solutions'}, {'question': 'Can you explain the DINO-World Model and its significance in AI planning?', 'citations': ['7291225769026936834'], 'grading_notes': '- DINO-World enables complex action sequence planning\\n- Uses action-conditioned world model from off-line data\\n- Pure planning without reinforcement learning\\n- Implements JEPA architecture with DINOv2 encoder\\n- Detailed resources available (website, paper, code)'}, {'question': 'What advancements or trends do you foresee in AI, especially in areas like deep learning and neural nets?', 'citations': ['7268343234450358272', '7060629056785895424'], 'grading_notes': '- Mention history of AI and neural nets\\n- Discuss advancements like convolutional nets, transformers\\n- Highlight self-supervised learning value\\n- Explain JEPAs importance\\n- Consider AI limitations and practical advice'}, {'question': 'How does physics connect to ML in your work?', 'citations': ['7213155813262004224'], 'grading_notes': '- Connect ML methods to physics origins\\n- Mention Lagrangian saddle point and classical mechanics\\n- Refer to 1987 PhD thesis and 1988 paper\\n- Credit NYU colleague Andrew Gordon Wilson'}, {'question': 'Can you explain your definition of a world model in AI?', 'citations': ['7165738293223931904'], 'grading_notes': '- Define world model with observations and actions\\n- Explain role of encoder and predictor\\n- Highlight latent variable importance\\n- Train on observation triplets\\n- Simplify for auto-regressive models'}, {'question': 'How do you view the role of open-source AI platforms in the growth of the startup ecosystem?', 'citations': ['7157046328219357184'], 'grading_notes': \"- Highlight open-source platforms as startup catalysts\\n- Emphasize vibrant AI startup ecosystem in France\\n- Mention Meta models' contribution to growth\\n- Note importance of open-source adoption\\n- Recognize impact on AI innovation\"}, {'question': 'What is your perspective on the balance between theory and empirical science in AI?', 'citations': ['7109879287490469889'], 'grading_notes': \"- Critique blind trust in theory\\n- Balance theory with empirical science\\n- Relevance of engineering in AI\\n- Theory shows what's impossible, but limits possibilities\\n- Deep learning belongs to engineering science\"}, {'question': 'What are your thoughts on the future of AI?', 'citations': ['7060629056785895424'], 'grading_notes': \"- Discuss AI in context of societal impact\\n- Highlight collaboration between AI and philosophy\\n- Mention role of education in AI development\\n- Reflect on AI's influence on future decision-making\\n- Emphasize interdisciplinary discussions\"}, {'question': 'What are your thoughts on improving LLM reliability with planning techniques?', 'citations': ['7133900073117061121'], 'grading_notes': '- Replace auto-regressive prediction with planning\\n- Many labs researching planning techniques\\n- Highlight key figures working on planning\\n- Mention deep learning for planning advocacy\\n- Ignore misinformation on Q*'}, {'question': \"What's your stance on open sourcing frontier AI models and their potential impact on society?\", 'citations': ['7195448948877066240', '7125928063019692032'], 'grading_notes': '- Advocate for open source AI platforms.\\n- Importance of diverse AI assistants.\\n- Address concerns about China with no threat.\\n- Warn against regulatory capture by corporations.\\n- Emphasize cultural diversity and economic development.'}, {'question': 'What insights do you have about the contributions of notable figures at Bell Labs in advancing computing and physical sciences?', 'citations': ['7316680799259418624'], 'grading_notes': \"- Celebrate Bell Labs Centennial with notable figures\\n- Highlight Al Aho's Turing Award and contributions\\n- Mention Horst Stormer's Nobel Prize and discovery\\n- Note Steve Chu's Nobel Prize and laser cooling work\\n- Emphasize Bell Labs' collaborative research culture\"}, {'question': 'What is your opinion on the influence of social media platforms like Facebook and Instagram on political beliefs and polarization?', 'citations': ['7091042830789345280'], 'grading_notes': '- Highlight limited impact of altered feeds\\n- Reference collaboration by NYU and UT Austin\\n- Mention study conducted during 2020 US elections\\n- Emphasize wide collaboration and methodology\\n- Note the study published in reputable journals'}, {'question': 'What are your thoughts on the current limitations of machine learning and future directions to achieve human-level AI?', 'citations': ['7144009727520251904'], 'grading_notes': '- Current ML lacks human-like efficiency \\n- Open platforms accelerate AI progress\\n- Concerns on AI cultural representation\\n- Open research to outpace potential misuse\\n- AI motivations differ from human motivations'}, {'question': 'What are your views on the limitations of LLMs and the potential of new AI architectures?', 'citations': ['7250915579228827648'], 'grading_notes': \"- Highlight LLMs' lack of physical understanding\\n- Mention LLMs' absence of persistent memory\\n- Emphasize reasoning and planning limitations\\n- Compare to animals' intelligent behavior\\n- Suggest potential in new AI architectures\"}, {'question': 'How can machines learn to plan and reason, and why do existing AI architectures fall short?', 'citations': ['7181917360302239746', '7093933657265975296', '7067849504774836226'], 'grading_notes': \"- Propose modular cognitive architecture for planning\\n- Emphasize predictive world model for action consequences\\n- Use H-JEPA for abstract representation learning\\n- Highlight self-supervised learning techniques\\n- Ensure system's controllability and safety\"}, {'question': 'What do you think about the safety of open-source AI models compared to closed ones?', 'citations': ['7154096829742157826'], 'grading_notes': '- Critique fear of open-source AI\\n- Highlight applications from open-source LLMs\\n- No AI catastrophe post-Llama-2\\n- Implies safety in open-source models\\n- Skepticism toward AI doomsday predictions'}, {'question': 'What are your thoughts on the importance of sharing innovations in science and technology?', 'citations': ['7291098987984539648'], 'grading_notes': \"- Critique of Silicon Valley's superiority complex\\n- Highlight importance of sharing innovations\\n- Emphasize large-scale collaboration\\n- Advocate for open source and publication\\n- Critique outdated patent system\"}, {'question': 'What are your views on combating AI-generated disinformation?', 'citations': ['7144419400920551424'], 'grading_notes': '- Consult academic experts on disinformation\\n- Value expertise over sensationalism\\n- Suggest credible sources like Arvind Narayanan and Josh Tucker\\n- Prioritize information from informed, serious academics\\n- Reject scaremongering from grifters'}, {'question': \"What are your thoughts on the premature takedown of Meta's Galactica due to AI ethics concerns?\", 'citations': ['7130214818862567424'], 'grading_notes': '- Condemnation of premature criticism based on hallucination fears\\n- Highlight misuse of AI ethics for negative impact\\n- Stress potential benefits for scientific community\\n- Call out destructive groupthink behavior\\n- Advocate measured and informed discourse'}, {'question': 'What do you think about the future of AI?', 'citations': ['7060629056785895424'], 'grading_notes': \"- Mention AI's current status and future prospects\\n- Highlight interdisciplinary discussions \\n- Reference event or collaboration details\\n- Note the involvement of academic institutions\\n- Indicate participant engagement in dialogues\"}, {'question': 'What are your thoughts on the impact of political actions on scientific progress and how it relates to AI ethics?', 'citations': ['7304871267281571840'], 'grading_notes': '- Highlight impact of political actions on scientists\\n- Emphasize freedom of speech concerns\\n- Discuss historical example of misconduct\\n- Address consequences of expelling scientists\\n- Consider implications for AI ethics'}, {'question': 'What is your perspective on the limitations of LLMs and the potential of sensory data for AI learning?', 'citations': ['7156484065603280896', '7133567569684238336', '7172266619103080448'], 'grading_notes': '- LLMs limited by low-bandwidth text data\\n- Sensory data provides high-bandwidth learning\\n- Greater redundancy in visual data aids learning\\n- Emulate human efficiency with new architectures\\n- High-bandwidth sensory data essential for human-level AI'}, {'question': 'What impact do you think open-source LLMs like Llama have on the AI industry?', 'citations': ['7087104028718903296', '7221538840405012482', '7234974269200306176'], 'grading_notes': '- Llama-v2 licensed for commercial use\\n- Open source enables widespread adoption\\n- Pretrained models with multiple parameters\\n- Llama 3.1 features and partner ecosystem\\n- Dominant platform with diverse user base'}, {'question': \"What are your thoughts on Meta's open-source AI strategy and its impact on the industry?\", 'citations': ['7202788469956296705'], 'grading_notes': \"- Open-source strategy revitalizes Zuckerberg's image\\n- Meta's strategy fosters new industry ecosystem\\n- Perception shift: Meta as positive force\\n- Tech community embraces Meta's AI approach\\n- Highlight industry impact of open-source AI\"}]\n"
     ]
    }
   ],
   "source": [
    "from json import load\n",
    "\n",
    "with open('../yann-lecun-wisdom/yann_test.json', 'r') as f:\n",
    "    data = load(f)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas_experimental import BaseModel\n",
    "\n",
    "class TestDataset(BaseModel):\n",
    "    question: str\n",
    "    citations: list[str]\n",
    "    grading_notes: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "RAGAS_APP_TOKEN = \"\"\n",
    "RAGAS_API_BASE_URL = \"https://api.dev.app.ragas.io\"\n",
    "\n",
    "os.environ[\"RAGAS_APP_TOKEN\"] = RAGAS_APP_TOKEN\n",
    "os.environ[\"RAGAS_API_BASE_URL\"] = RAGAS_API_BASE_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas_experimental import Project\n",
    "\n",
    "# p = Project.create(\n",
    "#     name=\"yann-lecun-wisdom\",\n",
    "#     description=\"Yann LeCun Wisdom\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"1ef0843b-231f-4a2c-b64d-d39bcee9d830\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Project(name='yann-lecun-wisdom')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Project(project_id=PROJECT_ID)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do you actually need to pass a model here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(name=yann-lecun-wisdom-dataset, model=TestDataset, len=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dataset = p.create_dataset(name=\"yann-lecun-wisdom-dataset\", model=TestDataset)\n",
    "test_dataset = p.get_dataset(dataset_id=\"8572180f-fddf-46c5-b943-e6ff6448eb01\", model=TestDataset)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: here there is a problem: how do you batch upload a test dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for item in data:\n",
    "    t = TestDataset(question=item[\"question\"], citations=item[\"citations\"], grading_notes=item[\"grading_notes\"])\n",
    "    # test_dataset.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fail'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# de\n",
    "from ragas_experimental.llm import ragas_llm\n",
    "from ragas_experimental.metric import DiscreteMetric\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "llm = ragas_llm(provider=\"openai\",model=\"gpt-4o\",client=AsyncOpenAI())\n",
    "\n",
    "my_metric = DiscreteMetric(\n",
    "    llm=llm,\n",
    "    name='correctness',\n",
    "    prompt=\"Given the Question: {query} \\n Evaluate if given answer {response} \\n based on the Grading notes\\n: {grading_notes}.\",\n",
    "    values=[\"pass\",\"fail\"],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# test LLM as judge\n",
    "result = my_metric.score(query=\"what is your response\", response=\"this is my response\",grading_notes=\"- response should not contains word response\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas_experimental.metric import MetricResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linkedin_ai.main import LinkedinAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md             yann_profile.json\n",
      "yann-lecun_posts.json yann_test.json\n"
     ]
    }
   ],
   "source": [
    "!ls ../yann-lecun-wisdom/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 437 LinkedIn posts\n",
      "BM25 index initialized\n"
     ]
    }
   ],
   "source": [
    "my_ai = await LinkedinAI.from_bm25('../yann-lecun-wisdom/yann-lecun_posts.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/14 20:57:18 WARNING mlflow.tracing.processor.mlflow: Creating a trace within the default experiment with id '0'. It is strongly recommended to not use the default experiment to log traces due to ambiguous search results and probable performance issues over time due to directory table listing performance degradation with high volumes of directories within a specific path. To avoid performance and disambiguation issues, set the experiment for your environment using `mlflow.set_experiment()` API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The context provided includes discussions on AI, open source, and the nature of science. Here are some key points:\\n\\n1. **AI and Open Source**: Yann LeCun emphasizes the importance of AI systems being open source, similar to the infrastructure of the Internet. He argues that AI assistants, which will mediate our digital interactions, should be open and crowd-sourced to ensure they are trustworthy and contain all human culture and knowledge. This is why Meta made Llama-2 open source.\\n\\n2. **Microsoft's Stance**: There is a critique of Microsoft President Brad Smith's comments, which seem to misrepresent the concept of open source by comparing the ownership structures of Meta and OpenAI. LeCun suggests that Microsoft's stance is reminiscent of its past anti-open source position, despite its current use of Linux in Azure.\\n\\n3. **Debate on Science**: A debate involving Yann LeCun and Elon Musk is highlighted, focusing on the definition of science. The discussion underscores the importance of objective discourse in scientific endeavors, as opposed to merely expressing opinions.\\n\\n4. **Meta's Response to NTIA**: Meta's response to the NTIA emphasizes the significance of open foundation models for U.S. interests, suggesting that openness in AI development is crucial for economic and national security.\\n\\nOverall, the context suggests a strong advocacy for open source in AI development and a call for objective, open discussions in scientific and technological fields.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await my_ai.ask(\"what is your response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentModel(TestDataset):\n",
    "    response: str\n",
    "    score: str\n",
    "    score_reason: str\n",
    "\n",
    "@p.experiment(ExperimentModel)\n",
    "async def experiment_func(item: TestDataset):\n",
    "    response = await my_ai.ask(item.question)\n",
    "    score = await my_metric.ascore(query=item.question, response=response, grading_notes=item.grading_notes)\n",
    "    return ExperimentModel(question=item.question, citations=item.citations, grading_notes=item.grading_notes, response=response, score=score.result, score_reason=score.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExperimentModel(question='What are your views on LLM limitations and their ability to generalize?', citations=['7085498609558843392'], grading_notes=\"- LLMs can't generalize like humans.\\n- AI systems can't yet mimic human understanding.\\n- Highlight AI's limitations in text memorization.\\n- Current AI lacks adaptability to new contexts.\", response='Based on the provided context, it seems that there is a recognition of the limitations of LLMs (Large Language Models) in terms of their ability to generalize. In Post 2, a quote from Melanie Michell highlights that the assumptions we make for humans, such as the ability to generalize understanding to new situations, are not yet appropriate for AI systems like LLMs. Additionally, in Post 3, there is an expression of opinion on the limitations of LLMs, noting that they lack certain features of intelligent behavior, such as understanding the physical world, having persistent memory, reasoning, and planning. These limitations suggest that while LLMs can process and generate text, their ability to generalize and exhibit intelligent behavior akin to humans or even animals is limited.', score='pass', score_reason=\"The answer recognizes the limitations of LLMs in generalizing, as it discusses their inability to generalize like humans and the lack of human-like understanding. It clearly highlights that while LLMs can handle text, they don't exhibit intelligent behavior akin to humans or animals. It fits well with the grading notes, emphasizing the models' limitations in understanding, text memorization, and adaptability to new contexts.\")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = await experiment_func(test_dataset[0])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:07<00:00,  4.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Experiment(name=kind_hamilton, model=ExperimentModel)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await experiment_func.run_async(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'haDDwxhEhWq4'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]._row_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
