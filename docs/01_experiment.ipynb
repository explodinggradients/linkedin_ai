{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook\n",
    "- create dataset\n",
    "- create llm as judge\n",
    "- run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'question': 'What are your views on LLM limitations and their ability to generalize?', 'citations': ['7085498609558843392'], 'grading_notes': \"- LLMs can't generalize like humans.\\n- AI systems can't yet mimic human understanding.\\n- Highlight AI's limitations in text memorization.\\n- Current AI lacks adaptability to new contexts.\"}, {'question': \"What are Yann LeCun's thoughts on the future steps in AI, particularly the usefulness and limitations of current LLMs?\", 'citations': ['7140695461815820289', '7060629056785895424'], 'grading_notes': \"- Current LLMs have limitations but are still useful\\n- Discuss the balance between potential AI threats and benefits\\n- Outline practicality over perfection in AI\\n- Explore realistic AI advancements, not science fiction\\n- Encourage discussions on AI's current and future role\"}, {'question': 'How can countries like India foster AI innovation and development?', 'citations': ['7267674826373304322'], 'grading_notes': '- Suggest creating industry research labs with ambitions\\n- Use AI as an empirical science\\n- Address limitations of large language models\\n- Focus on world models, planning, and reasoning\\n- Encourage jumpstarting AI ecosystems'}, {'question': 'What are your views on the impact of political decisions on scientific research, specifically in the US?', 'citations': ['7303509065190551553'], 'grading_notes': '- Highlight funding cuts and resource reduction\\n- Mention staff firings and gag orders\\n- Discuss impact on scientific freedom\\n- Question long-term viability of US science\\n- Reflect on potential decline in scientific innovation'}, {'question': 'What are your opinions on receiving the Queen Elizabeth Prize for Engineering with respect to advancements in AI?', 'citations': ['7292877506095820803'], 'grading_notes': '- Honored by the Queen Elizabeth Prize recognition\\n- Shared prize with notable figures like Bengio, Hinton\\n- Prize focuses on engineering achievements\\n- Prestigious award in the engineering field\\n- Ceremony to attend in fall with royalty'}, {'question': 'What measures can Europe take to attract top AI scientists and researchers?', 'citations': ['7299096239625695232'], 'grading_notes': '- Emphasize competitive compensation and research freedom\\n- Highlight access to top students and collaborators\\n- Reduce administrative overhead for research funding\\n- Improve research facilities and industry collaboration\\n- Balance teaching and administrative duties'}, {'question': 'What are your current thoughts on the present and future of AI?', 'citations': ['7060629056785895424'], 'grading_notes': '- Focus on engineering challenges, not philosophical debates\\n- Highlight adaptability and transparent methods\\n- Promote user control and modular AI systems\\n- Emphasize empirical feedback and experimentation\\n- Encourage diverse, empowering solutions'}, {'question': 'Can you explain the DINO-World Model and its significance in AI planning?', 'citations': ['7291225769026936834'], 'grading_notes': '- DINO-World enables complex action sequence planning\\n- Uses action-conditioned world model from off-line data\\n- Pure planning without reinforcement learning\\n- Implements JEPA architecture with DINOv2 encoder\\n- Detailed resources available (website, paper, code)'}, {'question': 'What advancements or trends do you foresee in AI, especially in areas like deep learning and neural nets?', 'citations': ['7268343234450358272', '7060629056785895424'], 'grading_notes': '- Mention history of AI and neural nets\\n- Discuss advancements like convolutional nets, transformers\\n- Highlight self-supervised learning value\\n- Explain JEPAs importance\\n- Consider AI limitations and practical advice'}, {'question': 'How does physics connect to ML in your work?', 'citations': ['7213155813262004224'], 'grading_notes': '- Connect ML methods to physics origins\\n- Mention Lagrangian saddle point and classical mechanics\\n- Refer to 1987 PhD thesis and 1988 paper\\n- Credit NYU colleague Andrew Gordon Wilson'}, {'question': 'Can you explain your definition of a world model in AI?', 'citations': ['7165738293223931904'], 'grading_notes': '- Define world model with observations and actions\\n- Explain role of encoder and predictor\\n- Highlight latent variable importance\\n- Train on observation triplets\\n- Simplify for auto-regressive models'}, {'question': 'How do you view the role of open-source AI platforms in the growth of the startup ecosystem?', 'citations': ['7157046328219357184'], 'grading_notes': \"- Highlight open-source platforms as startup catalysts\\n- Emphasize vibrant AI startup ecosystem in France\\n- Mention Meta models' contribution to growth\\n- Note importance of open-source adoption\\n- Recognize impact on AI innovation\"}, {'question': 'What is your perspective on the balance between theory and empirical science in AI?', 'citations': ['7109879287490469889'], 'grading_notes': \"- Critique blind trust in theory\\n- Balance theory with empirical science\\n- Relevance of engineering in AI\\n- Theory shows what's impossible, but limits possibilities\\n- Deep learning belongs to engineering science\"}, {'question': 'What are your thoughts on the future of AI?', 'citations': ['7060629056785895424'], 'grading_notes': \"- Discuss AI in context of societal impact\\n- Highlight collaboration between AI and philosophy\\n- Mention role of education in AI development\\n- Reflect on AI's influence on future decision-making\\n- Emphasize interdisciplinary discussions\"}, {'question': 'What are your thoughts on improving LLM reliability with planning techniques?', 'citations': ['7133900073117061121'], 'grading_notes': '- Replace auto-regressive prediction with planning\\n- Many labs researching planning techniques\\n- Highlight key figures working on planning\\n- Mention deep learning for planning advocacy\\n- Ignore misinformation on Q*'}, {'question': \"What's your stance on open sourcing frontier AI models and their potential impact on society?\", 'citations': ['7195448948877066240', '7125928063019692032'], 'grading_notes': '- Advocate for open source AI platforms.\\n- Importance of diverse AI assistants.\\n- Address concerns about China with no threat.\\n- Warn against regulatory capture by corporations.\\n- Emphasize cultural diversity and economic development.'}, {'question': 'What insights do you have about the contributions of notable figures at Bell Labs in advancing computing and physical sciences?', 'citations': ['7316680799259418624'], 'grading_notes': \"- Celebrate Bell Labs Centennial with notable figures\\n- Highlight Al Aho's Turing Award and contributions\\n- Mention Horst Stormer's Nobel Prize and discovery\\n- Note Steve Chu's Nobel Prize and laser cooling work\\n- Emphasize Bell Labs' collaborative research culture\"}, {'question': 'What is your opinion on the influence of social media platforms like Facebook and Instagram on political beliefs and polarization?', 'citations': ['7091042830789345280'], 'grading_notes': '- Highlight limited impact of altered feeds\\n- Reference collaboration by NYU and UT Austin\\n- Mention study conducted during 2020 US elections\\n- Emphasize wide collaboration and methodology\\n- Note the study published in reputable journals'}, {'question': 'What are your thoughts on the current limitations of machine learning and future directions to achieve human-level AI?', 'citations': ['7144009727520251904'], 'grading_notes': '- Current ML lacks human-like efficiency \\n- Open platforms accelerate AI progress\\n- Concerns on AI cultural representation\\n- Open research to outpace potential misuse\\n- AI motivations differ from human motivations'}, {'question': 'What are your views on the limitations of LLMs and the potential of new AI architectures?', 'citations': ['7250915579228827648'], 'grading_notes': \"- Highlight LLMs' lack of physical understanding\\n- Mention LLMs' absence of persistent memory\\n- Emphasize reasoning and planning limitations\\n- Compare to animals' intelligent behavior\\n- Suggest potential in new AI architectures\"}, {'question': 'How can machines learn to plan and reason, and why do existing AI architectures fall short?', 'citations': ['7181917360302239746', '7093933657265975296', '7067849504774836226'], 'grading_notes': \"- Propose modular cognitive architecture for planning\\n- Emphasize predictive world model for action consequences\\n- Use H-JEPA for abstract representation learning\\n- Highlight self-supervised learning techniques\\n- Ensure system's controllability and safety\"}, {'question': 'What do you think about the safety of open-source AI models compared to closed ones?', 'citations': ['7154096829742157826'], 'grading_notes': '- Critique fear of open-source AI\\n- Highlight applications from open-source LLMs\\n- No AI catastrophe post-Llama-2\\n- Implies safety in open-source models\\n- Skepticism toward AI doomsday predictions'}, {'question': 'What are your thoughts on the importance of sharing innovations in science and technology?', 'citations': ['7291098987984539648'], 'grading_notes': \"- Critique of Silicon Valley's superiority complex\\n- Highlight importance of sharing innovations\\n- Emphasize large-scale collaboration\\n- Advocate for open source and publication\\n- Critique outdated patent system\"}, {'question': 'What are your views on combating AI-generated disinformation?', 'citations': ['7144419400920551424'], 'grading_notes': '- Consult academic experts on disinformation\\n- Value expertise over sensationalism\\n- Suggest credible sources like Arvind Narayanan and Josh Tucker\\n- Prioritize information from informed, serious academics\\n- Reject scaremongering from grifters'}, {'question': \"What are your thoughts on the premature takedown of Meta's Galactica due to AI ethics concerns?\", 'citations': ['7130214818862567424'], 'grading_notes': '- Condemnation of premature criticism based on hallucination fears\\n- Highlight misuse of AI ethics for negative impact\\n- Stress potential benefits for scientific community\\n- Call out destructive groupthink behavior\\n- Advocate measured and informed discourse'}, {'question': 'What do you think about the future of AI?', 'citations': ['7060629056785895424'], 'grading_notes': \"- Mention AI's current status and future prospects\\n- Highlight interdisciplinary discussions \\n- Reference event or collaboration details\\n- Note the involvement of academic institutions\\n- Indicate participant engagement in dialogues\"}, {'question': 'What are your thoughts on the impact of political actions on scientific progress and how it relates to AI ethics?', 'citations': ['7304871267281571840'], 'grading_notes': '- Highlight impact of political actions on scientists\\n- Emphasize freedom of speech concerns\\n- Discuss historical example of misconduct\\n- Address consequences of expelling scientists\\n- Consider implications for AI ethics'}, {'question': 'What is your perspective on the limitations of LLMs and the potential of sensory data for AI learning?', 'citations': ['7156484065603280896', '7133567569684238336', '7172266619103080448'], 'grading_notes': '- LLMs limited by low-bandwidth text data\\n- Sensory data provides high-bandwidth learning\\n- Greater redundancy in visual data aids learning\\n- Emulate human efficiency with new architectures\\n- High-bandwidth sensory data essential for human-level AI'}, {'question': 'What impact do you think open-source LLMs like Llama have on the AI industry?', 'citations': ['7087104028718903296', '7221538840405012482', '7234974269200306176'], 'grading_notes': '- Llama-v2 licensed for commercial use\\n- Open source enables widespread adoption\\n- Pretrained models with multiple parameters\\n- Llama 3.1 features and partner ecosystem\\n- Dominant platform with diverse user base'}, {'question': \"What are your thoughts on Meta's open-source AI strategy and its impact on the industry?\", 'citations': ['7202788469956296705'], 'grading_notes': \"- Open-source strategy revitalizes Zuckerberg's image\\n- Meta's strategy fosters new industry ecosystem\\n- Perception shift: Meta as positive force\\n- Tech community embraces Meta's AI approach\\n- Highlight industry impact of open-source AI\"}]\n"
     ]
    }
   ],
   "source": [
    "from json import load\n",
    "\n",
    "with open('yann-lecun-wisdom/yann_test.json', 'r') as f:\n",
    "    data = load(f)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas_experimental import BaseModel\n",
    "\n",
    "class TestDataset(BaseModel):\n",
    "    question: str\n",
    "    citations: list[str]\n",
    "    grading_notes: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "RAGAS_APP_TOKEN = \"your-app-token\"\n",
    "RAGAS_API_BASE_URL = \"https://api.dev.app.ragas.io\"\n",
    "\n",
    "os.environ[\"RAGAS_APP_TOKEN\"] = RAGAS_APP_TOKEN\n",
    "os.environ[\"RAGAS_API_BASE_URL\"] = RAGAS_API_BASE_URL\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas_experimental import Project\n",
    "\n",
    "p = Project.create(\n",
    "    name=\"yann-lecun-wisdom\",\n",
    "    description=\"Yann LeCun Wisdom\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch project id from link for now\n",
    "PROJECT_ID = \"919a4d42-aaf2-45cd-badd-152249788bfa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Project(name='yann-lecun-wisdom')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Project(project_id=PROJECT_ID)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do you actually need to pass a model here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(name=test-yann-lecun, model=TestDataset, len=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = p.create_dataset(name=\"test-yann-lecun\", model=TestDataset)\n",
    "# test_dataset = p.get_dataset(dataset_id=\"8572180f-fddf-46c5-b943-e6ff6448eb01\", model=TestDataset)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: here there is a problem: how do you batch upload a test dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for item in data:\n",
    "    t = TestDataset(question=item[\"question\"], citations=item[\"citations\"], grading_notes=item[\"grading_notes\"])\n",
    "    test_dataset.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fail'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# de\n",
    "from ragas_experimental.llm import ragas_llm\n",
    "from ragas_experimental.metric import DiscreteMetric\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "llm = ragas_llm(provider=\"openai\",model=\"gpt-4o\",client=AsyncOpenAI())\n",
    "\n",
    "my_metric = DiscreteMetric(\n",
    "    llm=llm,\n",
    "    name='correctness',\n",
    "    prompt=\"Given the Question: {query} \\n Evaluate if given answer {response} \\n based on the Grading notes\\n: {grading_notes}.\",\n",
    "    values=[\"pass\",\"fail\"],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# test LLM as judge\n",
    "result = my_metric.score(query=\"what is your response\", response=\"this is my response\",grading_notes=\"- response should not contains word response\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linkedin_ai import LinkedinAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 437 LinkedIn posts\n",
      "BM25 index initialized\n"
     ]
    }
   ],
   "source": [
    "my_ai = await LinkedinAI.from_bm25('yann-lecun-wisdom/yann-lecun_posts.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My response is centered around the importance of open access and open-source models in AI development. I believe that our interactions with the digital world will increasingly be mediated by AI assistants, which will eventually become smarter than us. These AI systems should be open and open-source, similar to the software infrastructure of the Internet, to ensure they serve as a common infrastructure containing all human culture and knowledge. This is why Meta made Llama-2 open and free.\\n\\nIn a panel discussion at the Paris Peace Forum, I emphasized the need for these systems to be crowd-sourced, akin to Wikipedia, to ensure transparency and inclusivity. I also addressed a misconception about open access and open source, particularly in response to comments from Microsoft President Brad Smith, who seemed to misrepresent these concepts. Open access and open source are crucial for fostering innovation and trust in AI technologies.\\n\\nAdditionally, in Meta's official response to the NTIA, we highlighted the significance of open foundation models to U.S. economic, national security, and foreign policy interests. This underscores the broader impact and necessity of maintaining openness in AI development.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await my_ai.ask(\"what is your response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentModel(TestDataset):\n",
    "    response: str\n",
    "    score: str\n",
    "    score_reason: str\n",
    "\n",
    "@p.experiment(ExperimentModel)\n",
    "async def experiment_func(item: TestDataset):\n",
    "    response = await my_ai.ask(item.question)\n",
    "    score = await my_metric.ascore(query=item.question, response=response, grading_notes=item.grading_notes)\n",
    "    return ExperimentModel(question=item.question, citations=item.citations, grading_notes=item.grading_notes, response=response, score=score.result, score_reason=score.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExperimentModel(question='What are your views on LLM limitations and their ability to generalize?', citations=['7085498609558843392'], grading_notes=\"- LLMs can't generalize like humans.\\n- AI systems can't yet mimic human understanding.\\n- Highlight AI's limitations in text memorization.\\n- Current AI lacks adaptability to new contexts.\", response='Large Language Models (LLMs) have significant limitations, particularly in their ability to generalize. As discussed in a fantastic piece by Melanie Michell, the assumptions we make for humans—such as not being able to memorize vast collections of text and being able to generalize understanding to new situations—are not yet appropriate for AI systems. LLMs lack the ability to understand the physical world, have persistent memory, reason, and plan, which are essential features of intelligent behavior. These are capabilities that even your cat possesses, but LLMs do not. Therefore, while LLMs are powerful in certain contexts, their ability to generalize is limited, and new architectures are needed to overcome these limitations.', score='pass', score_reason=\"The response effectively addresses the LLM limitations, emphasizing that they cannot generalize like humans do. It highlights AI's limitations in understanding, text memorization, and adaptability to new contexts, in line with the grading notes.\")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = await experiment_func(test_dataset[0])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:07<00:00,  3.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Experiment(name=xenodochial_hoare, model=ExperimentModel)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await experiment_func.run_async(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "superme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
