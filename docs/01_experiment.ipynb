{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook\n",
    "- create dataset\n",
    "- create llm as judge\n",
    "- run experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your first project and upload test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import load\n",
    "\n",
    "with open('yann-lecun-wisdom/yann_test.json', 'r') as f:\n",
    "    data = load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas_experimental import BaseModel\n",
    "\n",
    "class TestDataset(BaseModel):\n",
    "    question: str\n",
    "    citations: list[str]\n",
    "    grading_notes: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "RAGAS_APP_TOKEN = \"your-app-token\"\n",
    "RAGAS_API_BASE_URL = \"https://api.dev.app.ragas.io\"\n",
    "\n",
    "os.environ[\"RAGAS_APP_TOKEN\"] = RAGAS_APP_TOKEN\n",
    "os.environ[\"RAGAS_API_BASE_URL\"] = RAGAS_API_BASE_URL\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas_experimental import Project\n",
    "\n",
    "p = Project.create(\n",
    "    name=\"yann-lecun-wisdom\",\n",
    "    description=\"Yann LeCun Wisdom\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch project id from link for now\n",
    "PROJECT_ID = \"919a4d42-aaf2-45cd-badd-152249788bfa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Project(name='yann-lecun-wisdom')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Project(project_id=PROJECT_ID)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do you actually need to pass a model here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(name=test-yann-lecun, model=TestDataset, len=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = p.create_dataset(name=\"test-yann-lecun\", model=TestDataset)\n",
    "# test_dataset = p.get_dataset(dataset_id=\"8572180f-fddf-46c5-b943-e6ff6448eb01\", model=TestDataset)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: here there is a problem: how do you batch upload a test dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for item in data:\n",
    "    t = TestDataset(question=item[\"question\"], citations=item[\"citations\"], grading_notes=item[\"grading_notes\"])\n",
    "    test_dataset.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create LLM as judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fail'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# de\n",
    "from ragas_experimental.llm import ragas_llm\n",
    "from ragas_experimental.metric import DiscreteMetric\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "llm = ragas_llm(provider=\"openai\",model=\"gpt-4o\",client=AsyncOpenAI())\n",
    "\n",
    "my_metric = DiscreteMetric(\n",
    "    llm=llm,\n",
    "    name='correctness',\n",
    "    prompt=\"Given the Question: {query} \\n Evaluate if given answer {response} \\n based on the Grading notes\\n: {grading_notes}.\",\n",
    "    values=[\"pass\",\"fail\"],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# test LLM as judge\n",
    "result = my_metric.score(query=\"what is your response\", response=\"this is my response\",grading_notes=\"- response should not contains word response\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linkedin_ai import LinkedinAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 437 LinkedIn posts\n",
      "BM25 index initialized\n"
     ]
    }
   ],
   "source": [
    "my_ai = await LinkedinAI.from_bm25('yann-lecun-wisdom/yann-lecun_posts.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My response is centered around the importance of open access and open-source models in AI development. I believe that our interactions with the digital world will increasingly be mediated by AI assistants, which will eventually become smarter than us. These AI systems should be open and open-source, similar to the software infrastructure of the Internet, to ensure they serve as a common infrastructure containing all human culture and knowledge. This is why Meta made Llama-2 open and free.\\n\\nIn a panel discussion at the Paris Peace Forum, I emphasized the need for these systems to be crowd-sourced, akin to Wikipedia, to ensure transparency and inclusivity. I also addressed a misconception about open access and open source, particularly in response to comments from Microsoft President Brad Smith, who seemed to misrepresent these concepts. Open access and open source are crucial for fostering innovation and trust in AI technologies.\\n\\nAdditionally, in Meta's official response to the NTIA, we highlighted the significance of open foundation models to U.S. economic, national security, and foreign policy interests. This underscores the broader impact and necessity of maintaining openness in AI development.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await my_ai.ask(\"what is your response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentModel(TestDataset):\n",
    "    response: str\n",
    "    score: str\n",
    "    score_reason: str\n",
    "\n",
    "@p.experiment(ExperimentModel)\n",
    "async def experiment_func(item: TestDataset):\n",
    "    response = await my_ai.ask(item.question)\n",
    "    score = await my_metric.ascore(query=item.question, response=response, grading_notes=item.grading_notes)\n",
    "    return ExperimentModel(question=item.question, citations=item.citations, grading_notes=item.grading_notes, response=response, score=score.result, score_reason=score.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExperimentModel(question='What are your views on LLM limitations and their ability to generalize?', citations=['7085498609558843392'], grading_notes=\"- LLMs can't generalize like humans.\\n- AI systems can't yet mimic human understanding.\\n- Highlight AI's limitations in text memorization.\\n- Current AI lacks adaptability to new contexts.\", response='Large Language Models (LLMs) have significant limitations, particularly in their ability to generalize. As discussed in a fantastic piece by Melanie Michell, the assumptions we make for humans—such as not being able to memorize vast collections of text and being able to generalize understanding to new situations—are not yet appropriate for AI systems. LLMs lack the ability to understand the physical world, have persistent memory, reason, and plan, which are essential features of intelligent behavior. These are capabilities that even your cat possesses, but LLMs do not. Therefore, while LLMs are powerful in certain contexts, their ability to generalize is limited, and new architectures are needed to overcome these limitations.', score='pass', score_reason=\"The response effectively addresses the LLM limitations, emphasizing that they cannot generalize like humans do. It highlights AI's limitations in understanding, text memorization, and adaptability to new contexts, in line with the grading notes.\")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = await experiment_func(test_dataset[0])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:07<00:00,  3.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Experiment(name=xenodochial_hoare, model=ExperimentModel)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await experiment_func.run_async(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "superme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
