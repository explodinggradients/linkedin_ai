{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from linkedin_ai import LinkedinAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yann-lecun-wisdom'...\n",
      "remote: Enumerating objects: 13, done.\u001b[K\n",
      "remote: Total 13 (delta 0), reused 0 (delta 0), pack-reused 13 (from 1)\u001b[K\n",
      "Unpacking objects: 100% (13/13), 95.26 KiB | 4.54 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://huggingface.co/datasets/explodinggradients/yann-lecun-wisdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 437 LinkedIn posts\n",
      "BM25 index initialized\n"
     ]
    }
   ],
   "source": [
    "my_ai = await LinkedinAI.from_bm25(posts=\"yann-lecun-wisdom/yann-lecun_posts.json\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/15 13:34:08 WARNING mlflow.tracing.processor.mlflow: Creating a trace within the default experiment with id '0'. It is strongly recommended to not use the default experiment to log traces due to ambiguous search results and probable performance issues over time due to directory table listing performance degradation with high volumes of directories within a specific path. To avoid performance and disambiguation issues, set the experiment for your environment using `mlflow.set_experiment()` API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Open source AI models, particularly large language models (LLMs), have shown a tremendous capacity for innovation and application development. Since the release of models like Llama-2, we've witnessed an explosion of applications built on top of these open source LLMs. Contrary to the predictions of AI doomers, none of the catastrophic scenarios they envisioned have materialized. This suggests that open source models are not inherently more dangerous than closed ones and can, in fact, drive significant progress and creativity in the field.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await my_ai.ask(\"What are your thoughts on OSS LLMs?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed source LLMs have their place, but I believe that open source AI models offer significant advantages. Since the release of Llama-2, we've seen an explosion of applications built on top of open source LLMs, and none of the catastrophic scenarios predicted by AI doomers have materialized. Open source models foster innovation and collaboration, allowing a broader community to contribute to their development and application. This can lead to more robust and versatile AI systems. However, it's important to recognize that both open and closed models have their roles, depending on the context and requirements of the application.\n"
     ]
    }
   ],
   "source": [
    "print(await my_ai.ask(\"What are your thoughts on closed source LLMs?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "superme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
