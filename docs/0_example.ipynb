{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinkedIn AI: Getting Started\n",
    "\n",
    "This notebook will guide you through the basic usage of the LinkedIn AI package. \n",
    "\n",
    "You'll: \n",
    "- Set up your environment\n",
    "- Load LinkedIn post data\n",
    "- Interacting with your AI assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Set Up Your Environment\n",
    "\n",
    "First, let's import the necessary packages and set your OpenAI API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from linkedin_ai import LinkedinAI\n",
    "\n",
    "# Set your OpenAI API key as an environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Getting the Data\n",
    "\n",
    "Let's download a dataset containing the LinkedIn posts from Yann LeCun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yann-lecun-wisdom'...\n",
      "remote: Enumerating objects: 13, done.\u001b[K\n",
      "remote: Total 13 (delta 0), reused 0 (delta 0), pack-reused 13 (from 1)\u001b[K\n",
      "Unpacking objects: 100% (13/13), 95.26 KiB | 524.00 KiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "# Clone the sample dataset repository\n",
    "!git clone https://huggingface.co/datasets/explodinggradients/yann-lecun-wisdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset will be saved in a folder called `yann-lecun-wisdom`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Initialize Your AI Assistant with BM25 Retrieval\n",
    "\n",
    "Now, let's create an AI assistant that can answer questions based on these posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 437 LinkedIn posts\n",
      "BM25 index initialized\n"
     ]
    }
   ],
   "source": [
    "my_ai = await LinkedinAI.from_bm25(posts=\"yann-lecun-wisdom/yann-lecun_posts.json\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created an instance of LinkedinAI, using the from_bm25 method. \n",
    "\n",
    "This method:- \n",
    "- Initializes the assistant with the BM25 algorithm for document retrieval. \n",
    "- Loads all the LinkedIn posts from the JSON file and builds an index for quick retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Ask Your First Question\n",
    "Let's ask a question about open-source language models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/17 16:38:12 WARNING mlflow.tracing.processor.mlflow: Creating a trace within the default experiment with id '0'. It is strongly recommended to not use the default experiment to log traces due to ambiguous search results and probable performance issues over time due to directory table listing performance degradation with high volumes of directories within a specific path. To avoid performance and disambiguation issues, set the experiment for your environment using `mlflow.set_experiment()` API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open source AI models, particularly large language models (LLMs), have shown significant potential and have led to a surge in applications since the release of models like Llama-2. Contrary to the fears of some AI doomers, these open source models have not resulted in catastrophic scenarios. Instead, they have fostered innovation and development in the AI community. The idea that open source models are inherently more dangerous than closed ones is increasingly being challenged by the positive outcomes we've observed.\n"
     ]
    }
   ],
   "source": [
    "response = await my_ai.ask(\"What are your thoughts on OSS LLMs?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed source LLMs have their place, but I believe that open source AI models offer significant advantages. Since the release of Llama-2, we've seen an explosion of applications built on open source LLMs, and none of the catastrophic scenarios predicted by AI doomers have materialized. Open source models foster innovation and collaboration, allowing a broader community to contribute to their development and application. This openness can lead to more robust and versatile AI systems. However, it's important to recognize that both open and closed models have their roles, and the choice between them depends on the specific needs and goals of a project.\n"
     ]
    }
   ],
   "source": [
    "response = await my_ai.ask(\"What are your thoughts on closed source LLMs?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "Now that you've got the basics down, Let's move on to the experiment notebook to learn how to evaluate your AI assistant"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datadog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
